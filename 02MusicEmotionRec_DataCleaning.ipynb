{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BegEZcrn-zs-",
        "outputId": "376d7fab-74dd-46e8-d7b9-94d84f3449d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# UNCOMMENT this in colab\n",
        "\n",
        "# ##### xiyah #####\n",
        "# # mount google drive\n",
        "# # since I uploaded all data into google drive.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# # install librosa\n",
        "# # after installation can comment out\n",
        "# # \"-q > /dev/null\" helps hide the install message\n",
        "# !pip install librosa -q > /dev/null\n",
        "# ##### xiyah #####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "27ID8I82-p0M"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import os\n",
        "import librosa\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# used for storing features into files\n",
        "import pickle\n",
        "\n",
        "# used for calculating statistical features\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# imports for model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXAJkxiJeFil"
      },
      "source": [
        "## Drop Useless Data (**You can skip this step, since all the data after drops are saved**)\n",
        "\n",
        "drop those data which are:   \n",
        "\n",
        "- not a 1d vector or a scalar\n",
        "- not useful for training(\"xs\", \"srs\")\n",
        "\n",
        "**You can skip this step, since all the data after drops are saved**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iN7Yis0N-nY1"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset/all_features_q2_mod.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# np.load\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data_q1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(q1_path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m data_q2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq2_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m data_q3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(q3_path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m data_q4 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(q4_path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/anaconda3/envs/dm/lib/python3.12/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/all_features_q2_mod.npy'"
          ]
        }
      ],
      "source": [
        "# load .npy\n",
        "q1_path = \"/content/drive/MyDrive/EN.553.602DataMiningSpring2024/dataset/all_features_q1_mod.npy\"\n",
        "q2_path = \"/content/drive/MyDrive/EN.553.602DataMiningSpring2024/dataset/all_features_q2_mod.npy\"\n",
        "q3_path = \"/content/drive/MyDrive/EN.553.602DataMiningSpring2024/dataset/all_features_q3_mod.npy\"\n",
        "q4_path = \"/content/drive/MyDrive/EN.553.602DataMiningSpring2024/dataset/all_features_q4_mod.npy\"\n",
        "\n",
        "# np.load\n",
        "data_q1 = np.load(q1_path, allow_pickle=True)\n",
        "data_q2 = np.load(q2_path, allow_pickle=True)\n",
        "data_q3 = np.load(q3_path, allow_pickle=True)\n",
        "data_q4 = np.load(q4_path, allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edgpABKO_9NI"
      },
      "outputs": [],
      "source": [
        "# define a columns' names variable\n",
        "df_columns = ['xs', 'srs',\n",
        "              'chroma_stft_demos', 'chroma_cqt_demos', 'chroma_vqt_demos', 'chroma_cens_demos', \\\n",
        "              'melspectrogram_demos', 'mfcc_demos', 'rms_demos', \\\n",
        "              'spectral_centroid_demos', 'spectral_bandwidth_demos', 'spectral_contrast_demos', 'spectral_flatness_demos', 'spectral_rolloff_demos', \\\n",
        "              'tonnetz_demos', 'zero_crossing_rate_demos', 'tempo', 'tempogram_ratio', 'labels', \\\n",
        "              'chroma_stft_mean', 'chroma_stft_std', 'chroma_stft_sum', 'chroma_stft_skew', 'chroma_stft_kurtosis', \\\n",
        "              'chroma_cqt_mean', 'chroma_cqt_std', 'chroma_cqt_sum', 'chroma_cqt_skew', 'chroma_cqt_kurtosis', \\\n",
        "              'chroma_vqt_mean', 'chroma_vqt_std', 'chroma_vqt_sum', 'chroma_vqt_skew', 'chroma_vqt_kurtosis', \\\n",
        "              'melspectrogram_mean', 'melspectrogram_std', 'melspectrogram_min', 'melspectrogram_max', 'melspectrogram_sum', 'melspectrogram_skew', 'melspectrogram_kurtosis', \\\n",
        "              'mfcc_mean', 'mfcc_std', 'mfcc_min', 'mfcc_max', 'mfcc_skew', 'mfcc_kurtosis', 'mfcc_median', \\\n",
        "              'rms_mean', 'rms_std', 'rms_min', 'rms_max', 'rms_skew', 'rms_kurtosis', \\\n",
        "              'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_centroid_min', 'spectral_centroid_max', 'spectral_centroid_skew', 'spectral_centroid_kurtosis', \\\n",
        "              'spectral_bandwidth_mean', 'spectral_bandwidth_std', 'spectral_bandwidth_min', 'spectral_bandwidth_max', 'spectral_bandwidth_skew', 'spectral_bandwidth_kurtosis', \\\n",
        "              'spectral_contrast_mean', 'spectral_contrast_std', 'spectral_contrast_min', 'spectral_contrast_max', 'spectral_contrast_skew', 'spectral_contrast_kurtosis', 'spectral_contrast_range', \\\n",
        "              'spectral_flatness_mean', 'spectral_flatness_std', 'spectral_flatness_min', 'spectral_flatness_max', 'spectral_flatness_skew', 'spectral_flatness_kurtosis', 'spectral_flatness_range', \\\n",
        "              'spectral_rolloff_mean', 'spectral_rolloff_std', 'spectral_rolloff_min', 'spectral_rolloff_max', 'spectral_rolloff_skew', 'spectral_rolloff_kurtosis', 'spectral_rolloff_range', \\\n",
        "              'tonnetz_mean', 'tonnetz_std', 'tonnetz_min', 'tonnetz_max', 'tonnetz_skew', 'tonnetz_kurtosis', 'tonnetz_range', \\\n",
        "              'zero_crossing_rate_mean', 'zero_crossing_rate_std', 'zero_crossing_rate_min', 'zero_crossing_rate_max', 'zero_crossing_rate_skew', 'zero_crossing_rate_kurtosis', 'zero_crossing_rate_range']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYhEPmVlDE00"
      },
      "outputs": [],
      "source": [
        "### Xiyah ###\n",
        "# convert all .npy to pd.DataFrame\n",
        "df_q1 = pd.DataFrame(data_q1, columns=df_columns)\n",
        "df_q2 = pd.DataFrame(data_q2, columns=df_columns)\n",
        "df_q3 = pd.DataFrame(data_q3, columns=df_columns)\n",
        "df_q4 = pd.DataFrame(data_q4, columns=df_columns)\n",
        "#df_q1.head()\n",
        "### Xiyah ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FGNloPaXxDW",
        "outputId": "bca56ab4-5321-479e-86ab-ebf78d441f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "columns to drop: ['chroma_stft_demos', 'chroma_cqt_demos', 'chroma_vqt_demos', 'chroma_cens_demos', 'melspectrogram_demos', 'mfcc_demos', 'rms_demos', 'spectral_centroid_demos', 'spectral_bandwidth_demos', 'spectral_contrast_demos', 'spectral_flatness_demos', 'spectral_rolloff_demos', 'tonnetz_demos', 'zero_crossing_rate_demos', 'tempogram_ratio']\n"
          ]
        }
      ],
      "source": [
        "### Xiyah ###\n",
        "# Get shape of all columns\n",
        "# Function to get the shape of each element\n",
        "def get_shape(element):\n",
        "    # Check if the element is a NumPy array\n",
        "    if hasattr(element, 'shape'):\n",
        "        return element.shape\n",
        "    # Check if the element is iterable (like a list) but not a string\n",
        "    elif hasattr(element, '__iter__') and not isinstance(element, str):\n",
        "        return len(element),\n",
        "    # Handle non-iterable objects (like integers)\n",
        "    else:\n",
        "        return ()  # Return an empty tuple or another placeholder indicating non-iterable objects\n",
        "\n",
        "# Apply `get_shape` to only the first row\n",
        "shape_info_q1 = df_q1.iloc[0].apply(get_shape)\n",
        "\n",
        "#print(shape_info_q1)\n",
        "\n",
        "# Filter columns where the shape is not of length 0 or 1, indicating they are not scalars or 1D vectors\n",
        "cols_to_drop = shape_info_q1[shape_info_q1.apply(len) > 1].index.tolist()\n",
        "\n",
        "print(f\"columns to drop: {cols_to_drop}\")\n",
        "### Xiyah ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrrbsvDrcBHQ"
      },
      "outputs": [],
      "source": [
        "### Xiyah ###\n",
        "# drop all columns that are not 1d or scalars: we already have their mathematical features\n",
        "df_q1 = df_q1.drop(columns=cols_to_drop)\n",
        "df_q2 = df_q2.drop(columns=cols_to_drop)\n",
        "df_q3 = df_q3.drop(columns=cols_to_drop)\n",
        "df_q4 = df_q4.drop(columns=cols_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eJMvsP3ctth"
      },
      "outputs": [],
      "source": [
        "# After inspection, we will also drop xs and srs, they are only useful for featurization\n",
        "df_q1 = df_q1.drop(columns=['xs', 'srs'])\n",
        "df_q2 = df_q2.drop(columns=['xs', 'srs'])\n",
        "df_q3 = df_q3.drop(columns=['xs', 'srs'])\n",
        "df_q4 = df_q4.drop(columns=['xs', 'srs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpgQxjEEdP3t"
      },
      "outputs": [],
      "source": [
        "# re-order columns, move labels as the last column\n",
        "# Get a list of all column names except 'labels'\n",
        "cols_no_labels_q1 = [col for col in df_q1.columns if col != 'labels']\n",
        "cols_no_labels_q2 = [col for col in df_q2.columns if col != 'labels']\n",
        "cols_no_labels_q3 = [col for col in df_q3.columns if col != 'labels']\n",
        "cols_no_labels_q4 = [col for col in df_q4.columns if col != 'labels']\n",
        "\n",
        "# Append 'labels' to the end of the column list\n",
        "new_cols_q1 = cols_no_labels_q1 + ['labels']\n",
        "new_cols_q2 = cols_no_labels_q2 + ['labels']\n",
        "new_cols_q3 = cols_no_labels_q3 + ['labels']\n",
        "new_cols_q4 = cols_no_labels_q4 + ['labels']\n",
        "\n",
        "# Reorder the DataFrame columns\n",
        "df_q1 = df_q1[new_cols_q1]\n",
        "df_q2 = df_q2[new_cols_q2]\n",
        "df_q3 = df_q3[new_cols_q3]\n",
        "df_q4 = df_q4[new_cols_q4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bny-NMF0ccBx",
        "outputId": "e7cc143d-a85a-4a86-814d-f467f41e2860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_q1.shape: (225, 84)\n",
            "df_q2.shape: (225, 84)\n",
            "df_q3.shape: (225, 84)\n",
            "df_q4.shape: (225, 84)\n"
          ]
        }
      ],
      "source": [
        "print(f\"df_q1.shape: {df_q1.shape}\")\n",
        "print(f\"df_q2.shape: {df_q2.shape}\")\n",
        "print(f\"df_q3.shape: {df_q3.shape}\")\n",
        "print(f\"df_q4.shape: {df_q4.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "mgG7FgiKevDi",
        "outputId": "86a44445-949e-423b-97a8-221e248cc50d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_q1"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-54e568c3-4735-41de-894b-8255cda78d55\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tempo</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_std</th>\n",
              "      <th>chroma_stft_sum</th>\n",
              "      <th>chroma_stft_skew</th>\n",
              "      <th>chroma_stft_kurtosis</th>\n",
              "      <th>chroma_cqt_mean</th>\n",
              "      <th>chroma_cqt_std</th>\n",
              "      <th>chroma_cqt_sum</th>\n",
              "      <th>chroma_cqt_skew</th>\n",
              "      <th>...</th>\n",
              "      <th>tonnetz_kurtosis</th>\n",
              "      <th>tonnetz_range</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_std</th>\n",
              "      <th>zero_crossing_rate_min</th>\n",
              "      <th>zero_crossing_rate_max</th>\n",
              "      <th>zero_crossing_rate_skew</th>\n",
              "      <th>zero_crossing_rate_kurtosis</th>\n",
              "      <th>zero_crossing_rate_range</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[129.19921875]</td>\n",
              "      <td>[0.3402438, 0.4108848, 0.32207942, 0.43924117,...</td>\n",
              "      <td>[0.25901443, 0.34396023, 0.24817161, 0.3390962...</td>\n",
              "      <td>5754.600098</td>\n",
              "      <td>[0.99369633, 0.6889807, 1.1558719, 0.51363957,...</td>\n",
              "      <td>[0.18223047, -1.0339843, 0.7369144, -1.18541, ...</td>\n",
              "      <td>[0.37230334, 0.59613794, 0.349376, 0.5221062, ...</td>\n",
              "      <td>[0.1650009, 0.28621086, 0.17438404, 0.24190375...</td>\n",
              "      <td>7482.439453</td>\n",
              "      <td>[1.1793867, 0.19034995, 1.4648391, 0.5109394, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.2676932002114798, -0.2611242959606561, -0....</td>\n",
              "      <td>[0.39503816324089674, 0.44382569880070666, 0.6...</td>\n",
              "      <td>[0.1439822635135135]</td>\n",
              "      <td>[0.06052925895431856]</td>\n",
              "      <td>[0.03125]</td>\n",
              "      <td>[0.564453125]</td>\n",
              "      <td>[2.299913592613744]</td>\n",
              "      <td>[9.972581240443636]</td>\n",
              "      <td>[0.533203125]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[161.4990234375]</td>\n",
              "      <td>[0.36104006, 0.2428113, 0.33913192, 0.41598046...</td>\n",
              "      <td>[0.3057084, 0.21803722, 0.26099977, 0.31606582...</td>\n",
              "      <td>5868.901367</td>\n",
              "      <td>[0.8817804, 1.4171929, 0.9687368, 0.77790874, ...</td>\n",
              "      <td>[-0.35459352, 1.3924265, 0.051932335, -0.83470...</td>\n",
              "      <td>[0.39986077, 0.30028376, 0.41042277, 0.5339542...</td>\n",
              "      <td>[0.2795176, 0.11410666, 0.1324839, 0.23995899,...</td>\n",
              "      <td>6873.734375</td>\n",
              "      <td>[1.3378943, 1.0632907, 0.9806561, 0.91683173, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4546138798763306, -0.5757695864820596, 0.0...</td>\n",
              "      <td>[0.42942833816117487, 0.4362426048761109, 0.52...</td>\n",
              "      <td>[0.10062665902509653]</td>\n",
              "      <td>[0.06195558099185238]</td>\n",
              "      <td>[0.0126953125]</td>\n",
              "      <td>[0.53857421875]</td>\n",
              "      <td>[2.4103148531571437]</td>\n",
              "      <td>[10.632752706921927]</td>\n",
              "      <td>[0.52587890625]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[99.38401442307692]</td>\n",
              "      <td>[0.3350637, 0.4391525, 0.3131803, 0.36769086, ...</td>\n",
              "      <td>[0.23067027, 0.34413788, 0.2166038, 0.3000164,...</td>\n",
              "      <td>5885.837891</td>\n",
              "      <td>[0.63521445, 0.6002824, 0.6111119, 0.9701896, ...</td>\n",
              "      <td>[-0.44197345, -1.1731204, -0.6007376, -0.27134...</td>\n",
              "      <td>[0.2838195, 0.55256397, 0.23260526, 0.35447538...</td>\n",
              "      <td>[0.13484542, 0.31740782, 0.123309836, 0.267685...</td>\n",
              "      <td>6406.210449</td>\n",
              "      <td>[1.078106, 0.44249153, 1.7751677, 1.425022, 1....</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.07777779783759664, -0.66986980775311, -0.57...</td>\n",
              "      <td>[0.549337563990827, 0.45787447752394766, 0.692...</td>\n",
              "      <td>[0.06854375301640926]</td>\n",
              "      <td>[0.03186446827069103]</td>\n",
              "      <td>[0.01806640625]</td>\n",
              "      <td>[0.21875]</td>\n",
              "      <td>[1.0653329036995505]</td>\n",
              "      <td>[1.313176804637732]</td>\n",
              "      <td>[0.20068359375]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[123.046875]</td>\n",
              "      <td>[0.20232584, 0.4100135, 0.2596639, 0.14443561,...</td>\n",
              "      <td>[0.15172842, 0.36189678, 0.26187456, 0.1126129...</td>\n",
              "      <td>4598.774902</td>\n",
              "      <td>[1.5267997, 0.74306566, 1.7494311, 1.5250498, ...</td>\n",
              "      <td>[3.3818812, -1.0821086, 2.2402334, 3.302959, 1...</td>\n",
              "      <td>[0.19787204, 0.38152912, 0.2595981, 0.18471201...</td>\n",
              "      <td>[0.11222625, 0.2533469, 0.15406808, 0.10194606...</td>\n",
              "      <td>4871.200684</td>\n",
              "      <td>[1.6630076, 1.2764502, 1.5215753, 1.4900329, 1...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.689955821707545, 0.011593890255965356, -0....</td>\n",
              "      <td>[0.6551601962522167, 0.8039702548013667, 0.817...</td>\n",
              "      <td>[0.0696255127895753]</td>\n",
              "      <td>[0.016080018069265088]</td>\n",
              "      <td>[0.02978515625]</td>\n",
              "      <td>[0.1484375]</td>\n",
              "      <td>[0.7492532964882583]</td>\n",
              "      <td>[1.9720264141033086]</td>\n",
              "      <td>[0.11865234375]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[103.359375]</td>\n",
              "      <td>[0.20571218, 0.18657087, 0.284147, 0.23309906,...</td>\n",
              "      <td>[0.26805663, 0.24865834, 0.31335503, 0.2693379...</td>\n",
              "      <td>3841.712158</td>\n",
              "      <td>[1.8727081, 1.9668415, 1.3176929, 1.7174534, 1...</td>\n",
              "      <td>[2.6374311, 3.2114024, 0.471771, 2.033866, 0.9...</td>\n",
              "      <td>[0.4677634, 0.34280092, 0.41840968, 0.42241988...</td>\n",
              "      <td>[0.29720858, 0.25228196, 0.27344728, 0.2717988...</td>\n",
              "      <td>6369.010254</td>\n",
              "      <td>[0.54591733, 1.2141986, 0.8864644, 0.9038617, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[2.0776852407507347, 1.3959966015028629, 0.106...</td>\n",
              "      <td>[0.9353934797999381, 0.8043349604683768, 1.031...</td>\n",
              "      <td>[0.09968026061776061]</td>\n",
              "      <td>[0.039801127600770446]</td>\n",
              "      <td>[0.025390625]</td>\n",
              "      <td>[0.23291015625]</td>\n",
              "      <td>[0.24549962817541723]</td>\n",
              "      <td>[-0.5180193190257767]</td>\n",
              "      <td>[0.20751953125]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 84 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54e568c3-4735-41de-894b-8255cda78d55')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54e568c3-4735-41de-894b-8255cda78d55 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54e568c3-4735-41de-894b-8255cda78d55');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-888cf16e-603f-44af-8e84-eaff7cf405b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-888cf16e-603f-44af-8e84-eaff7cf405b1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-888cf16e-603f-44af-8e84-eaff7cf405b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                 tempo                                   chroma_stft_mean  \\\n",
              "0       [129.19921875]  [0.3402438, 0.4108848, 0.32207942, 0.43924117,...   \n",
              "1     [161.4990234375]  [0.36104006, 0.2428113, 0.33913192, 0.41598046...   \n",
              "2  [99.38401442307692]  [0.3350637, 0.4391525, 0.3131803, 0.36769086, ...   \n",
              "3         [123.046875]  [0.20232584, 0.4100135, 0.2596639, 0.14443561,...   \n",
              "4         [103.359375]  [0.20571218, 0.18657087, 0.284147, 0.23309906,...   \n",
              "\n",
              "                                     chroma_stft_std chroma_stft_sum  \\\n",
              "0  [0.25901443, 0.34396023, 0.24817161, 0.3390962...     5754.600098   \n",
              "1  [0.3057084, 0.21803722, 0.26099977, 0.31606582...     5868.901367   \n",
              "2  [0.23067027, 0.34413788, 0.2166038, 0.3000164,...     5885.837891   \n",
              "3  [0.15172842, 0.36189678, 0.26187456, 0.1126129...     4598.774902   \n",
              "4  [0.26805663, 0.24865834, 0.31335503, 0.2693379...     3841.712158   \n",
              "\n",
              "                                    chroma_stft_skew  \\\n",
              "0  [0.99369633, 0.6889807, 1.1558719, 0.51363957,...   \n",
              "1  [0.8817804, 1.4171929, 0.9687368, 0.77790874, ...   \n",
              "2  [0.63521445, 0.6002824, 0.6111119, 0.9701896, ...   \n",
              "3  [1.5267997, 0.74306566, 1.7494311, 1.5250498, ...   \n",
              "4  [1.8727081, 1.9668415, 1.3176929, 1.7174534, 1...   \n",
              "\n",
              "                                chroma_stft_kurtosis  \\\n",
              "0  [0.18223047, -1.0339843, 0.7369144, -1.18541, ...   \n",
              "1  [-0.35459352, 1.3924265, 0.051932335, -0.83470...   \n",
              "2  [-0.44197345, -1.1731204, -0.6007376, -0.27134...   \n",
              "3  [3.3818812, -1.0821086, 2.2402334, 3.302959, 1...   \n",
              "4  [2.6374311, 3.2114024, 0.471771, 2.033866, 0.9...   \n",
              "\n",
              "                                     chroma_cqt_mean  \\\n",
              "0  [0.37230334, 0.59613794, 0.349376, 0.5221062, ...   \n",
              "1  [0.39986077, 0.30028376, 0.41042277, 0.5339542...   \n",
              "2  [0.2838195, 0.55256397, 0.23260526, 0.35447538...   \n",
              "3  [0.19787204, 0.38152912, 0.2595981, 0.18471201...   \n",
              "4  [0.4677634, 0.34280092, 0.41840968, 0.42241988...   \n",
              "\n",
              "                                      chroma_cqt_std chroma_cqt_sum  \\\n",
              "0  [0.1650009, 0.28621086, 0.17438404, 0.24190375...    7482.439453   \n",
              "1  [0.2795176, 0.11410666, 0.1324839, 0.23995899,...    6873.734375   \n",
              "2  [0.13484542, 0.31740782, 0.123309836, 0.267685...    6406.210449   \n",
              "3  [0.11222625, 0.2533469, 0.15406808, 0.10194606...    4871.200684   \n",
              "4  [0.29720858, 0.25228196, 0.27344728, 0.2717988...    6369.010254   \n",
              "\n",
              "                                     chroma_cqt_skew  ...  \\\n",
              "0  [1.1793867, 0.19034995, 1.4648391, 0.5109394, ...  ...   \n",
              "1  [1.3378943, 1.0632907, 0.9806561, 0.91683173, ...  ...   \n",
              "2  [1.078106, 0.44249153, 1.7751677, 1.425022, 1....  ...   \n",
              "3  [1.6630076, 1.2764502, 1.5215753, 1.4900329, 1...  ...   \n",
              "4  [0.54591733, 1.2141986, 0.8864644, 0.9038617, ...  ...   \n",
              "\n",
              "                                    tonnetz_kurtosis  \\\n",
              "0  [-0.2676932002114798, -0.2611242959606561, -0....   \n",
              "1  [-0.4546138798763306, -0.5757695864820596, 0.0...   \n",
              "2  [0.07777779783759664, -0.66986980775311, -0.57...   \n",
              "3  [-0.689955821707545, 0.011593890255965356, -0....   \n",
              "4  [2.0776852407507347, 1.3959966015028629, 0.106...   \n",
              "\n",
              "                                       tonnetz_range zero_crossing_rate_mean  \\\n",
              "0  [0.39503816324089674, 0.44382569880070666, 0.6...    [0.1439822635135135]   \n",
              "1  [0.42942833816117487, 0.4362426048761109, 0.52...   [0.10062665902509653]   \n",
              "2  [0.549337563990827, 0.45787447752394766, 0.692...   [0.06854375301640926]   \n",
              "3  [0.6551601962522167, 0.8039702548013667, 0.817...    [0.0696255127895753]   \n",
              "4  [0.9353934797999381, 0.8043349604683768, 1.031...   [0.09968026061776061]   \n",
              "\n",
              "   zero_crossing_rate_std zero_crossing_rate_min zero_crossing_rate_max  \\\n",
              "0   [0.06052925895431856]              [0.03125]          [0.564453125]   \n",
              "1   [0.06195558099185238]         [0.0126953125]        [0.53857421875]   \n",
              "2   [0.03186446827069103]        [0.01806640625]              [0.21875]   \n",
              "3  [0.016080018069265088]        [0.02978515625]            [0.1484375]   \n",
              "4  [0.039801127600770446]          [0.025390625]        [0.23291015625]   \n",
              "\n",
              "  zero_crossing_rate_skew zero_crossing_rate_kurtosis  \\\n",
              "0     [2.299913592613744]         [9.972581240443636]   \n",
              "1    [2.4103148531571437]        [10.632752706921927]   \n",
              "2    [1.0653329036995505]         [1.313176804637732]   \n",
              "3    [0.7492532964882583]        [1.9720264141033086]   \n",
              "4   [0.24549962817541723]       [-0.5180193190257767]   \n",
              "\n",
              "  zero_crossing_rate_range labels  \n",
              "0            [0.533203125]      1  \n",
              "1          [0.52587890625]      1  \n",
              "2          [0.20068359375]      1  \n",
              "3          [0.11865234375]      1  \n",
              "4          [0.20751953125]      1  \n",
              "\n",
              "[5 rows x 84 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_q1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8oo5Nt-t129"
      },
      "outputs": [],
      "source": [
        "# save to .npy after drop\n",
        "df_q1_path = \"/content/drive/MyDrive/EN.553.602DataMiningSpring2024/dataset/data_afterDrop_q1.npy\"\n",
        "df_q2_path = \"/content/drive/MyDrive/EN.553.602DataMiningSpring2024/dataset/data_afterDrop_q2.npy\"\n",
        "df_q3_path = \"/content/drive/MyDrive/EN.553.602DataMiningSpring2024/dataset/data_afterDrop_q3.npy\"\n",
        "df_q4_path = \"/content/drive/MyDrive/EN.553.602DataMiningSpring2024/dataset/data_afterDrop_q4.npy\"\n",
        "# # to array\n",
        "arr_q1 = df_q1.to_numpy()\n",
        "arr_q2 = df_q2.to_numpy()\n",
        "arr_q3 = df_q3.to_numpy()\n",
        "arr_q4 = df_q4.to_numpy()\n",
        "# # save  (225, 84) for each\n",
        "np.save(df_q1_path, arr_q1, allow_pickle=True)\n",
        "np.save(df_q2_path, arr_q2, allow_pickle=True)\n",
        "np.save(df_q3_path, arr_q3, allow_pickle=True)\n",
        "np.save(df_q4_path, arr_q4, allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS6vEPDYu1re"
      },
      "outputs": [],
      "source": [
        "# try loading\n",
        "# np.load\n",
        "mod_data_q1 = np.load(df_q1_path, allow_pickle=True)\n",
        "mod_data_q2 = np.load(df_q2_path, allow_pickle=True)\n",
        "mod_data_q3 = np.load(df_q3_path, allow_pickle=True)\n",
        "mod_data_q4 = np.load(df_q4_path, allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP23cmf_xU9n",
        "outputId": "cd7695db-baf1-40b8-fe15-ba93a297aa5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['tempo', 'chroma_stft_mean', 'chroma_stft_std', 'chroma_stft_sum', 'chroma_stft_skew', 'chroma_stft_kurtosis', 'chroma_cqt_mean', 'chroma_cqt_std', 'chroma_cqt_sum', 'chroma_cqt_skew', 'chroma_cqt_kurtosis', 'chroma_vqt_mean', 'chroma_vqt_std', 'chroma_vqt_sum', 'chroma_vqt_skew', 'chroma_vqt_kurtosis', 'melspectrogram_mean', 'melspectrogram_std', 'melspectrogram_min', 'melspectrogram_max', 'melspectrogram_sum', 'melspectrogram_skew', 'melspectrogram_kurtosis', 'mfcc_mean', 'mfcc_std', 'mfcc_min', 'mfcc_max', 'mfcc_skew', 'mfcc_kurtosis', 'mfcc_median', 'rms_mean', 'rms_std', 'rms_min', 'rms_max', 'rms_skew', 'rms_kurtosis', 'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_centroid_min', 'spectral_centroid_max', 'spectral_centroid_skew', 'spectral_centroid_kurtosis', 'spectral_bandwidth_mean', 'spectral_bandwidth_std', 'spectral_bandwidth_min', 'spectral_bandwidth_max', 'spectral_bandwidth_skew', 'spectral_bandwidth_kurtosis', 'spectral_contrast_mean', 'spectral_contrast_std', 'spectral_contrast_min', 'spectral_contrast_max', 'spectral_contrast_skew', 'spectral_contrast_kurtosis', 'spectral_contrast_range', 'spectral_flatness_mean', 'spectral_flatness_std', 'spectral_flatness_min', 'spectral_flatness_max', 'spectral_flatness_skew', 'spectral_flatness_kurtosis', 'spectral_flatness_range', 'spectral_rolloff_mean', 'spectral_rolloff_std', 'spectral_rolloff_min', 'spectral_rolloff_max', 'spectral_rolloff_skew', 'spectral_rolloff_kurtosis', 'spectral_rolloff_range', 'tonnetz_mean', 'tonnetz_std', 'tonnetz_min', 'tonnetz_max', 'tonnetz_skew', 'tonnetz_kurtosis', 'tonnetz_range', 'zero_crossing_rate_mean', 'zero_crossing_rate_std', 'zero_crossing_rate_min', 'zero_crossing_rate_max', 'zero_crossing_rate_skew', 'zero_crossing_rate_kurtosis', 'zero_crossing_rate_range', 'labels']\n"
          ]
        }
      ],
      "source": [
        "print(list(df_q1.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJeFNGRvxiTQ"
      },
      "outputs": [],
      "source": [
        "# assign columns names\n",
        "cols = ['tempo', 'chroma_stft_mean', 'chroma_stft_std', 'chroma_stft_sum', 'chroma_stft_skew', 'chroma_stft_kurtosis',\n",
        "        'chroma_cqt_mean', 'chroma_cqt_std', 'chroma_cqt_sum', 'chroma_cqt_skew', 'chroma_cqt_kurtosis',\n",
        "        'chroma_vqt_mean', 'chroma_vqt_std', 'chroma_vqt_sum', 'chroma_vqt_skew', 'chroma_vqt_kurtosis',\n",
        "        'melspectrogram_mean', 'melspectrogram_std', 'melspectrogram_min', 'melspectrogram_max', 'melspectrogram_sum', 'melspectrogram_skew', 'melspectrogram_kurtosis',\n",
        "        'mfcc_mean', 'mfcc_std', 'mfcc_min', 'mfcc_max', 'mfcc_skew', 'mfcc_kurtosis', 'mfcc_median',\n",
        "        'rms_mean', 'rms_std', 'rms_min', 'rms_max', 'rms_skew', 'rms_kurtosis',\n",
        "        'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_centroid_min', 'spectral_centroid_max', 'spectral_centroid_skew', 'spectral_centroid_kurtosis',\n",
        "        'spectral_bandwidth_mean', 'spectral_bandwidth_std', 'spectral_bandwidth_min', 'spectral_bandwidth_max', 'spectral_bandwidth_skew', 'spectral_bandwidth_kurtosis',\n",
        "        'spectral_contrast_mean', 'spectral_contrast_std', 'spectral_contrast_min', 'spectral_contrast_max', 'spectral_contrast_skew', 'spectral_contrast_kurtosis', 'spectral_contrast_range',\n",
        "        'spectral_flatness_mean', 'spectral_flatness_std', 'spectral_flatness_min', 'spectral_flatness_max', 'spectral_flatness_skew', 'spectral_flatness_kurtosis', 'spectral_flatness_range',\n",
        "        'spectral_rolloff_mean', 'spectral_rolloff_std', 'spectral_rolloff_min', 'spectral_rolloff_max', 'spectral_rolloff_skew', 'spectral_rolloff_kurtosis', 'spectral_rolloff_range',\n",
        "        'tonnetz_mean', 'tonnetz_std', 'tonnetz_min', 'tonnetz_max', 'tonnetz_skew', 'tonnetz_kurtosis', 'tonnetz_range',\n",
        "        'zero_crossing_rate_mean', 'zero_crossing_rate_std', 'zero_crossing_rate_min', 'zero_crossing_rate_max', 'zero_crossing_rate_skew', 'zero_crossing_rate_kurtosis', 'zero_crossing_rate_range',\n",
        "        'labels']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbLxoVNdydWo"
      },
      "source": [
        "**End of dropping data's section.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ1SMTyDylyW"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "1. Data will be loaded as .npy format, don't neccessarily need to change it to .csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3x2A0Sic4Pew"
      },
      "outputs": [],
      "source": [
        "# You can start load data from here\n",
        "# save to .npy after drop\n",
        "df_q1_path = \"dataset/data_afterDrop_q1.npy\"\n",
        "df_q2_path = \"dataset/data_afterDrop_q2.npy\"\n",
        "df_q3_path = \"dataset/data_afterDrop_q3.npy\"\n",
        "df_q4_path = \"dataset/data_afterDrop_q4.npy\"\n",
        "\n",
        "# np.load\n",
        "mod_data_q1 = np.load(df_q1_path, allow_pickle=True)\n",
        "mod_data_q2 = np.load(df_q2_path, allow_pickle=True)\n",
        "mod_data_q3 = np.load(df_q3_path, allow_pickle=True)\n",
        "mod_data_q4 = np.load(df_q4_path, allow_pickle=True)\n",
        "\n",
        "# we have below columns\n",
        "cols = ['tempo', 'chroma_stft_mean', 'chroma_stft_std', 'chroma_stft_sum', 'chroma_stft_skew', 'chroma_stft_kurtosis',\n",
        "        'chroma_cqt_mean', 'chroma_cqt_std', 'chroma_cqt_sum', 'chroma_cqt_skew', 'chroma_cqt_kurtosis',\n",
        "        'chroma_vqt_mean', 'chroma_vqt_std', 'chroma_vqt_sum', 'chroma_vqt_skew', 'chroma_vqt_kurtosis',\n",
        "        'melspectrogram_mean', 'melspectrogram_std', 'melspectrogram_min', 'melspectrogram_max', 'melspectrogram_sum', 'melspectrogram_skew', 'melspectrogram_kurtosis',\n",
        "        'mfcc_mean', 'mfcc_std', 'mfcc_min', 'mfcc_max', 'mfcc_skew', 'mfcc_kurtosis', 'mfcc_median',\n",
        "        'rms_mean', 'rms_std', 'rms_min', 'rms_max', 'rms_skew', 'rms_kurtosis',\n",
        "        'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_centroid_min', 'spectral_centroid_max', 'spectral_centroid_skew', 'spectral_centroid_kurtosis',\n",
        "        'spectral_bandwidth_mean', 'spectral_bandwidth_std', 'spectral_bandwidth_min', 'spectral_bandwidth_max', 'spectral_bandwidth_skew', 'spectral_bandwidth_kurtosis',\n",
        "        'spectral_contrast_mean', 'spectral_contrast_std', 'spectral_contrast_min', 'spectral_contrast_max', 'spectral_contrast_skew', 'spectral_contrast_kurtosis', 'spectral_contrast_range',\n",
        "        'spectral_flatness_mean', 'spectral_flatness_std', 'spectral_flatness_min', 'spectral_flatness_max', 'spectral_flatness_skew', 'spectral_flatness_kurtosis', 'spectral_flatness_range',\n",
        "        'spectral_rolloff_mean', 'spectral_rolloff_std', 'spectral_rolloff_min', 'spectral_rolloff_max', 'spectral_rolloff_skew', 'spectral_rolloff_kurtosis', 'spectral_rolloff_range',\n",
        "        'tonnetz_mean', 'tonnetz_std', 'tonnetz_min', 'tonnetz_max', 'tonnetz_skew', 'tonnetz_kurtosis', 'tonnetz_range',\n",
        "        'zero_crossing_rate_mean', 'zero_crossing_rate_std', 'zero_crossing_rate_min', 'zero_crossing_rate_max', 'zero_crossing_rate_skew', 'zero_crossing_rate_kurtosis', 'zero_crossing_rate_range',\n",
        "        'labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(225, 84)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mod_data_q1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWTwdI71AFJL"
      },
      "source": [
        "## Check padding **No need to run! Already checked.**\n",
        "\n",
        "No need to do padding after checking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1jZoC2380fu"
      },
      "outputs": [],
      "source": [
        "# Initialize a list to hold the shape of the data for each feature\n",
        "feature_shapes_q1 = []\n",
        "feature_shapes_q2 = []\n",
        "feature_shapes_q3 = []\n",
        "feature_shapes_q4 = []\n",
        "\n",
        "# Assuming you have complex structures and data is loaded such that it supports iteration over features\n",
        "for feature_index in range(mod_data_q1.shape[1]):  # Iterate over features\n",
        "    # Extract all samples for this feature\n",
        "    samples = mod_data_q1[:, feature_index]\n",
        "\n",
        "    # Check if all elements in this feature have the same shape\n",
        "    shapes = set([np.array(sample).shape for sample in samples])\n",
        "\n",
        "    # Store the unique shapes found for this feature\n",
        "    feature_shapes_q1.append((feature_index, shapes))\n",
        "\n",
        "for feature_index in range(mod_data_q2.shape[1]):  # Iterate over features\n",
        "    # Extract all samples for this feature\n",
        "    samples = mod_data_q2[:, feature_index]\n",
        "\n",
        "    # Check if all elements in this feature have the same shape\n",
        "    shapes = set([np.array(sample).shape for sample in samples])\n",
        "\n",
        "    # Store the unique shapes found for this feature\n",
        "    feature_shapes_q2.append((feature_index, shapes))\n",
        "\n",
        "for feature_index in range(mod_data_q3.shape[1]):  # Iterate over features\n",
        "    # Extract all samples for this feature\n",
        "    samples = mod_data_q3[:, feature_index]\n",
        "\n",
        "    # Check if all elements in this feature have the same shape\n",
        "    shapes = set([np.array(sample).shape for sample in samples])\n",
        "\n",
        "    # Store the unique shapes found for this feature\n",
        "    feature_shapes_q3.append((feature_index, shapes))\n",
        "\n",
        "for feature_index in range(mod_data_q4.shape[1]):  # Iterate over features\n",
        "    # Extract all samples for this feature\n",
        "    samples = mod_data_q4[:, feature_index]\n",
        "\n",
        "    # Check if all elements in this feature have the same shape\n",
        "    shapes = set([np.array(sample).shape for sample in samples])\n",
        "\n",
        "    # Store the unique shapes found for this feature\n",
        "    feature_shapes_q4.append((feature_index, shapes))\n",
        "\n",
        "# Review the shapes for each feature\n",
        "for feature_index, shapes in feature_shapes_q1:\n",
        "    if len(shapes) > 1:\n",
        "        print(f\"Q1 Feature at index {feature_index} has varying shapes: {shapes}\")\n",
        "    # else:\n",
        "    #     print(f\"Feature at index {feature_index} has uniform shape: {shapes}\")\n",
        "\n",
        "for feature_index, shapes in feature_shapes_q2:\n",
        "    if len(shapes) > 1:\n",
        "        print(f\"Q2 Feature at index {feature_index} has varying shapes: {shapes}\")\n",
        "\n",
        "for feature_index, shapes in feature_shapes_q3:\n",
        "    if len(shapes) > 1:\n",
        "        print(f\"Q3 Feature at index {feature_index} has varying shapes: {shapes}\")\n",
        "\n",
        "for feature_index, shapes in feature_shapes_q4:\n",
        "    if len(shapes) > 1:\n",
        "        print(f\"Q4 Feature at index {feature_index} has varying shapes: {shapes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIYLTkiPASEx"
      },
      "source": [
        "The above cell checked for all q1, q2, q3, q4, for each feature, across 225 data the shape are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOiyGf0j7Kpc",
        "outputId": "4f12352c-f211-4f62-de06-d22ea388e54a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q1 No padding needed. All sequences have the same length.\n",
            "Q2 No padding needed. All sequences have the same length.\n",
            "Q3 No padding needed. All sequences have the same length.\n",
            "Q4 No padding needed. All sequences have the same length.\n"
          ]
        }
      ],
      "source": [
        "# decide whether need padding\n",
        "# Example for a list of arrays (if `data` is a list or an array of arrays)\n",
        "lengths_q1 = [seq.shape[0] for seq in mod_data_q1]  # Assuming sequences\n",
        "                                               # are the first dimension\n",
        "lengths_q2 = [seq.shape[0] for seq in mod_data_q2]\n",
        "lengths_q3 = [seq.shape[0] for seq in mod_data_q3]\n",
        "lengths_q4 = [seq.shape[0] for seq in mod_data_q4]\n",
        "\n",
        "# Check if all sequences have the same length\n",
        "if len(set(lengths_q1)) > 1:\n",
        "    print(\"Q1 Padding needed. Sequence lengths vary.\")\n",
        "else:\n",
        "    print(\"Q1 No padding needed. All sequences have the same length.\")\n",
        "# Check if all sequences have the same length\n",
        "if len(set(lengths_q2)) > 1:\n",
        "    print(\"Q2 Padding needed. Sequence lengths vary.\")\n",
        "else:\n",
        "    print(\"Q2 No padding needed. All sequences have the same length.\")\n",
        "# Check if all sequences have the same length\n",
        "if len(set(lengths_q3)) > 1:\n",
        "    print(\"Q3 Padding needed. Sequence lengths vary.\")\n",
        "else:\n",
        "    print(\"Q3 No padding needed. All sequences have the same length.\")\n",
        "# Check if all sequences have the same length\n",
        "if len(set(lengths_q4)) > 1:\n",
        "    print(\"Q4 Padding needed. Sequence lengths vary.\")\n",
        "else:\n",
        "    print(\"Q4 No padding needed. All sequences have the same length.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1k9JbTiRi4f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4MItLU2Bm2-"
      },
      "source": [
        "## Transfer loaded .npy into tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eNv37KkDBScf"
      },
      "outputs": [],
      "source": [
        "# TODO By 张北\n",
        "#融合四个q\n",
        "np_whole=np.vstack((np.vstack((np.vstack((mod_data_q1,mod_data_q2)),mod_data_q3)),mod_data_q4))\n",
        "df_whole = pd.DataFrame(np_whole,columns=cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "dkCoVq5eZjyG",
        "outputId": "ea22c695-3e5c-486d-bf40-38ff23b33d07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tempo</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_std</th>\n",
              "      <th>chroma_stft_sum</th>\n",
              "      <th>chroma_stft_skew</th>\n",
              "      <th>chroma_stft_kurtosis</th>\n",
              "      <th>chroma_cqt_mean</th>\n",
              "      <th>chroma_cqt_std</th>\n",
              "      <th>chroma_cqt_sum</th>\n",
              "      <th>chroma_cqt_skew</th>\n",
              "      <th>...</th>\n",
              "      <th>tonnetz_kurtosis</th>\n",
              "      <th>tonnetz_range</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_std</th>\n",
              "      <th>zero_crossing_rate_min</th>\n",
              "      <th>zero_crossing_rate_max</th>\n",
              "      <th>zero_crossing_rate_skew</th>\n",
              "      <th>zero_crossing_rate_kurtosis</th>\n",
              "      <th>zero_crossing_rate_range</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[129.19921875]</td>\n",
              "      <td>[0.3402438, 0.4108848, 0.32207942, 0.43924117,...</td>\n",
              "      <td>[0.25901443, 0.34396023, 0.24817161, 0.3390962...</td>\n",
              "      <td>5754.600098</td>\n",
              "      <td>[0.99369633, 0.6889807, 1.1558719, 0.51363957,...</td>\n",
              "      <td>[0.18223047, -1.0339843, 0.7369144, -1.18541, ...</td>\n",
              "      <td>[0.37230334, 0.59613794, 0.349376, 0.5221062, ...</td>\n",
              "      <td>[0.1650009, 0.28621086, 0.17438404, 0.24190375...</td>\n",
              "      <td>7482.439453</td>\n",
              "      <td>[1.1793867, 0.19034995, 1.4648391, 0.5109394, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.2676932002114798, -0.2611242959606561, -0....</td>\n",
              "      <td>[0.39503816324089674, 0.44382569880070666, 0.6...</td>\n",
              "      <td>[0.1439822635135135]</td>\n",
              "      <td>[0.06052925895431856]</td>\n",
              "      <td>[0.03125]</td>\n",
              "      <td>[0.564453125]</td>\n",
              "      <td>[2.299913592613744]</td>\n",
              "      <td>[9.972581240443636]</td>\n",
              "      <td>[0.533203125]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[161.4990234375]</td>\n",
              "      <td>[0.36104006, 0.2428113, 0.33913192, 0.41598046...</td>\n",
              "      <td>[0.3057084, 0.21803722, 0.26099977, 0.31606582...</td>\n",
              "      <td>5868.901367</td>\n",
              "      <td>[0.8817804, 1.4171929, 0.9687368, 0.77790874, ...</td>\n",
              "      <td>[-0.35459352, 1.3924265, 0.051932335, -0.83470...</td>\n",
              "      <td>[0.39986077, 0.30028376, 0.41042277, 0.5339542...</td>\n",
              "      <td>[0.2795176, 0.11410666, 0.1324839, 0.23995899,...</td>\n",
              "      <td>6873.734375</td>\n",
              "      <td>[1.3378943, 1.0632907, 0.9806561, 0.91683173, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.4546138798763306, -0.5757695864820596, 0.0...</td>\n",
              "      <td>[0.42942833816117487, 0.4362426048761109, 0.52...</td>\n",
              "      <td>[0.10062665902509653]</td>\n",
              "      <td>[0.06195558099185238]</td>\n",
              "      <td>[0.0126953125]</td>\n",
              "      <td>[0.53857421875]</td>\n",
              "      <td>[2.4103148531571437]</td>\n",
              "      <td>[10.632752706921927]</td>\n",
              "      <td>[0.52587890625]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[99.38401442307692]</td>\n",
              "      <td>[0.3350637, 0.4391525, 0.3131803, 0.36769086, ...</td>\n",
              "      <td>[0.23067027, 0.34413788, 0.2166038, 0.3000164,...</td>\n",
              "      <td>5885.837891</td>\n",
              "      <td>[0.63521445, 0.6002824, 0.6111119, 0.9701896, ...</td>\n",
              "      <td>[-0.44197345, -1.1731204, -0.6007376, -0.27134...</td>\n",
              "      <td>[0.2838195, 0.55256397, 0.23260526, 0.35447538...</td>\n",
              "      <td>[0.13484542, 0.31740782, 0.123309836, 0.267685...</td>\n",
              "      <td>6406.210449</td>\n",
              "      <td>[1.078106, 0.44249153, 1.7751677, 1.425022, 1....</td>\n",
              "      <td>...</td>\n",
              "      <td>[0.07777779783759664, -0.66986980775311, -0.57...</td>\n",
              "      <td>[0.549337563990827, 0.45787447752394766, 0.692...</td>\n",
              "      <td>[0.06854375301640926]</td>\n",
              "      <td>[0.03186446827069103]</td>\n",
              "      <td>[0.01806640625]</td>\n",
              "      <td>[0.21875]</td>\n",
              "      <td>[1.0653329036995505]</td>\n",
              "      <td>[1.313176804637732]</td>\n",
              "      <td>[0.20068359375]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[123.046875]</td>\n",
              "      <td>[0.20232584, 0.4100135, 0.2596639, 0.14443561,...</td>\n",
              "      <td>[0.15172842, 0.36189678, 0.26187456, 0.1126129...</td>\n",
              "      <td>4598.774902</td>\n",
              "      <td>[1.5267997, 0.74306566, 1.7494311, 1.5250498, ...</td>\n",
              "      <td>[3.3818812, -1.0821086, 2.2402334, 3.302959, 1...</td>\n",
              "      <td>[0.19787204, 0.38152912, 0.2595981, 0.18471201...</td>\n",
              "      <td>[0.11222625, 0.2533469, 0.15406808, 0.10194606...</td>\n",
              "      <td>4871.200684</td>\n",
              "      <td>[1.6630076, 1.2764502, 1.5215753, 1.4900329, 1...</td>\n",
              "      <td>...</td>\n",
              "      <td>[-0.689955821707545, 0.011593890255965356, -0....</td>\n",
              "      <td>[0.6551601962522167, 0.8039702548013667, 0.817...</td>\n",
              "      <td>[0.0696255127895753]</td>\n",
              "      <td>[0.016080018069265088]</td>\n",
              "      <td>[0.02978515625]</td>\n",
              "      <td>[0.1484375]</td>\n",
              "      <td>[0.7492532964882583]</td>\n",
              "      <td>[1.9720264141033086]</td>\n",
              "      <td>[0.11865234375]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[103.359375]</td>\n",
              "      <td>[0.20571218, 0.18657087, 0.284147, 0.23309906,...</td>\n",
              "      <td>[0.26805663, 0.24865834, 0.31335503, 0.2693379...</td>\n",
              "      <td>3841.712158</td>\n",
              "      <td>[1.8727081, 1.9668415, 1.3176929, 1.7174534, 1...</td>\n",
              "      <td>[2.6374311, 3.2114024, 0.471771, 2.033866, 0.9...</td>\n",
              "      <td>[0.4677634, 0.34280092, 0.41840968, 0.42241988...</td>\n",
              "      <td>[0.29720858, 0.25228196, 0.27344728, 0.2717988...</td>\n",
              "      <td>6369.010254</td>\n",
              "      <td>[0.54591733, 1.2141986, 0.8864644, 0.9038617, ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[2.0776852407507347, 1.3959966015028629, 0.106...</td>\n",
              "      <td>[0.9353934797999381, 0.8043349604683768, 1.031...</td>\n",
              "      <td>[0.09968026061776061]</td>\n",
              "      <td>[0.039801127600770446]</td>\n",
              "      <td>[0.025390625]</td>\n",
              "      <td>[0.23291015625]</td>\n",
              "      <td>[0.24549962817541723]</td>\n",
              "      <td>[-0.5180193190257767]</td>\n",
              "      <td>[0.20751953125]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 84 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tempo                                   chroma_stft_mean  \\\n",
              "0       [129.19921875]  [0.3402438, 0.4108848, 0.32207942, 0.43924117,...   \n",
              "1     [161.4990234375]  [0.36104006, 0.2428113, 0.33913192, 0.41598046...   \n",
              "2  [99.38401442307692]  [0.3350637, 0.4391525, 0.3131803, 0.36769086, ...   \n",
              "3         [123.046875]  [0.20232584, 0.4100135, 0.2596639, 0.14443561,...   \n",
              "4         [103.359375]  [0.20571218, 0.18657087, 0.284147, 0.23309906,...   \n",
              "\n",
              "                                     chroma_stft_std chroma_stft_sum  \\\n",
              "0  [0.25901443, 0.34396023, 0.24817161, 0.3390962...     5754.600098   \n",
              "1  [0.3057084, 0.21803722, 0.26099977, 0.31606582...     5868.901367   \n",
              "2  [0.23067027, 0.34413788, 0.2166038, 0.3000164,...     5885.837891   \n",
              "3  [0.15172842, 0.36189678, 0.26187456, 0.1126129...     4598.774902   \n",
              "4  [0.26805663, 0.24865834, 0.31335503, 0.2693379...     3841.712158   \n",
              "\n",
              "                                    chroma_stft_skew  \\\n",
              "0  [0.99369633, 0.6889807, 1.1558719, 0.51363957,...   \n",
              "1  [0.8817804, 1.4171929, 0.9687368, 0.77790874, ...   \n",
              "2  [0.63521445, 0.6002824, 0.6111119, 0.9701896, ...   \n",
              "3  [1.5267997, 0.74306566, 1.7494311, 1.5250498, ...   \n",
              "4  [1.8727081, 1.9668415, 1.3176929, 1.7174534, 1...   \n",
              "\n",
              "                                chroma_stft_kurtosis  \\\n",
              "0  [0.18223047, -1.0339843, 0.7369144, -1.18541, ...   \n",
              "1  [-0.35459352, 1.3924265, 0.051932335, -0.83470...   \n",
              "2  [-0.44197345, -1.1731204, -0.6007376, -0.27134...   \n",
              "3  [3.3818812, -1.0821086, 2.2402334, 3.302959, 1...   \n",
              "4  [2.6374311, 3.2114024, 0.471771, 2.033866, 0.9...   \n",
              "\n",
              "                                     chroma_cqt_mean  \\\n",
              "0  [0.37230334, 0.59613794, 0.349376, 0.5221062, ...   \n",
              "1  [0.39986077, 0.30028376, 0.41042277, 0.5339542...   \n",
              "2  [0.2838195, 0.55256397, 0.23260526, 0.35447538...   \n",
              "3  [0.19787204, 0.38152912, 0.2595981, 0.18471201...   \n",
              "4  [0.4677634, 0.34280092, 0.41840968, 0.42241988...   \n",
              "\n",
              "                                      chroma_cqt_std chroma_cqt_sum  \\\n",
              "0  [0.1650009, 0.28621086, 0.17438404, 0.24190375...    7482.439453   \n",
              "1  [0.2795176, 0.11410666, 0.1324839, 0.23995899,...    6873.734375   \n",
              "2  [0.13484542, 0.31740782, 0.123309836, 0.267685...    6406.210449   \n",
              "3  [0.11222625, 0.2533469, 0.15406808, 0.10194606...    4871.200684   \n",
              "4  [0.29720858, 0.25228196, 0.27344728, 0.2717988...    6369.010254   \n",
              "\n",
              "                                     chroma_cqt_skew  ...  \\\n",
              "0  [1.1793867, 0.19034995, 1.4648391, 0.5109394, ...  ...   \n",
              "1  [1.3378943, 1.0632907, 0.9806561, 0.91683173, ...  ...   \n",
              "2  [1.078106, 0.44249153, 1.7751677, 1.425022, 1....  ...   \n",
              "3  [1.6630076, 1.2764502, 1.5215753, 1.4900329, 1...  ...   \n",
              "4  [0.54591733, 1.2141986, 0.8864644, 0.9038617, ...  ...   \n",
              "\n",
              "                                    tonnetz_kurtosis  \\\n",
              "0  [-0.2676932002114798, -0.2611242959606561, -0....   \n",
              "1  [-0.4546138798763306, -0.5757695864820596, 0.0...   \n",
              "2  [0.07777779783759664, -0.66986980775311, -0.57...   \n",
              "3  [-0.689955821707545, 0.011593890255965356, -0....   \n",
              "4  [2.0776852407507347, 1.3959966015028629, 0.106...   \n",
              "\n",
              "                                       tonnetz_range zero_crossing_rate_mean  \\\n",
              "0  [0.39503816324089674, 0.44382569880070666, 0.6...    [0.1439822635135135]   \n",
              "1  [0.42942833816117487, 0.4362426048761109, 0.52...   [0.10062665902509653]   \n",
              "2  [0.549337563990827, 0.45787447752394766, 0.692...   [0.06854375301640926]   \n",
              "3  [0.6551601962522167, 0.8039702548013667, 0.817...    [0.0696255127895753]   \n",
              "4  [0.9353934797999381, 0.8043349604683768, 1.031...   [0.09968026061776061]   \n",
              "\n",
              "   zero_crossing_rate_std zero_crossing_rate_min zero_crossing_rate_max  \\\n",
              "0   [0.06052925895431856]              [0.03125]          [0.564453125]   \n",
              "1   [0.06195558099185238]         [0.0126953125]        [0.53857421875]   \n",
              "2   [0.03186446827069103]        [0.01806640625]              [0.21875]   \n",
              "3  [0.016080018069265088]        [0.02978515625]            [0.1484375]   \n",
              "4  [0.039801127600770446]          [0.025390625]        [0.23291015625]   \n",
              "\n",
              "  zero_crossing_rate_skew zero_crossing_rate_kurtosis  \\\n",
              "0     [2.299913592613744]         [9.972581240443636]   \n",
              "1    [2.4103148531571437]        [10.632752706921927]   \n",
              "2    [1.0653329036995505]         [1.313176804637732]   \n",
              "3    [0.7492532964882583]        [1.9720264141033086]   \n",
              "4   [0.24549962817541723]       [-0.5180193190257767]   \n",
              "\n",
              "  zero_crossing_rate_range labels  \n",
              "0            [0.533203125]      1  \n",
              "1          [0.52587890625]      1  \n",
              "2          [0.20068359375]      1  \n",
              "3          [0.11865234375]      1  \n",
              "4          [0.20751953125]      1  \n",
              "\n",
              "[5 rows x 84 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_whole.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz0MGjeVRlx9",
        "outputId": "2f62f841-0117-4227-ac53-a9a5756b997e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "demo_x.shape: torch.Size([900, 1187])\n",
            "demo_y.shape: torch.Size([900])\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "# demo_x - x prepared for training NN\n",
        "# demo_y - labels for NN predicted output to compare\n",
        "demo_x = df_whole[[col for col in df_whole.columns if col != 'labels']]\n",
        "demo_y = df_whole[\"labels\"]\n",
        "tensor_list = torch.tensor(np.stack(demo_x['tempo'].values), dtype=torch.float)\n",
        "for i in cols[1:-1]:\n",
        "  #设置报错函数 如果是类似sum的格式，无法用第一个的格式，就走except里面的，问题，为什么只有四个sum，其他数据的sum没有写吗\n",
        "  #答，因为其他数据sum之后没有意义，所以没有写sum\n",
        "  try:\n",
        "    current_tensor = torch.tensor(np.stack(demo_x[i].values), dtype=torch.float)\n",
        "    tensor_list = torch.cat((tensor_list, current_tensor), dim=1)\n",
        "  except:\n",
        "    current_tensor_numeric = pd.to_numeric(demo_x[i], errors='coerce')\n",
        "    current_tensor_numpy = np.array(current_tensor_numeric, dtype=float)\n",
        "    current_tensor = torch.tensor(current_tensor_numpy, dtype=torch.float)\n",
        "    demo_sum_unsqez = current_tensor.unsqueeze(1)\n",
        "    tensor_list = torch.cat((tensor_list, demo_sum_unsqez), dim=1)\n",
        "\n",
        "print(f\"demo_x.shape: {tensor_list.shape}\")\n",
        "\n",
        "\n",
        "demo_y_num = pd.to_numeric(demo_y, errors='coerce')\n",
        "demo_y_array = np.array(demo_y_num, dtype=float)\n",
        "demo_y = torch.tensor(demo_y_array, dtype=torch.float)\n",
        "demo_y = demo_y - 1  # Shift labels from 1, 2, 3, 4 to 0, 1, 2, 3\n",
        "print(f\"demo_y.shape: {demo_y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCmuxFnEfzg-"
      },
      "source": [
        "## Demo train on NN (**You don't need to run these cells**)\n",
        "\n",
        "**TODO** **====**   \n",
        "\n",
        "!!! Need to finally view whether needs to pad data(whether they have same dimension within the same feature) !!!\n",
        "\n",
        "  _solved_: Already checked, no need to pad. 2024.03.05 Xiyah\n",
        "\n",
        "!!! They are all run based on **pandas.DataFrame**. Now we have all data loaded as .npy, if in practical, need to figure out how to use .npy to direcly transfer to tensor. !!!\n",
        "\n",
        "!!! It is important to notice that, while spliting train and test data, needs to normalize train data first based on each features (do feature normalization) and the store the mean and variance results, so that we can use them(the train data mean and variance) while normalizing test data. !!!\n",
        "\n",
        "**====**\n",
        "\n",
        "We want to see whether the input containing both 1d vector and scalar can be trained in a NN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "PbW-o6DafQ4U",
        "outputId": "314624b9-67f5-4f42-ac8c-9c32e1e4b9e0"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d39b81670ab0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# simple example to see whether NN can train input containing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# both 1d vector and scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdemo_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod_data_q1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"chroma_stft_mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"chroma_stft_sum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdemo_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m### Xiyah ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ],
      "source": [
        "### Xiyah ###\n",
        "# simple example to see whether NN can train input containing\n",
        "# both 1d vector and scalar\n",
        "demo_data = df_q1[[\"chroma_stft_mean\", \"chroma_stft_sum\", \"labels\"]]\n",
        "demo_data.head()\n",
        "### Xiyah ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgkmsBqFgQBY"
      },
      "outputs": [],
      "source": [
        "# split x and y for demo\n",
        "# x: anything except \"labels\"\n",
        "# y: \"labels\": {1, 2, 3, 4}\n",
        "demo_x = demo_data[[col for col in demo_data.columns if col != 'labels']]\n",
        "demo_y = demo_data[\"labels\"]\n",
        "#demo_x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5BccowdgD3z",
        "outputId": "adbb3f9a-68a1-457c-fec2-8debffeda9b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([225, 13])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Xiyah ###\n",
        "# Adapt inputs to tensor\n",
        "\n",
        "## Convert chroma_stft_mean to a tensor\n",
        "# Stack the list of np.arrays to create a single np.array of shape (225, 12)\n",
        "demo_stft_mean_tensor = torch.tensor(np.stack(demo_x['chroma_stft_mean'].values), dtype=torch.float)\n",
        "\n",
        "## Convert chroma_stft_sum to a tensor\n",
        "# Since these are scalar values, we can directly convert the column to a np.array, then to a tensor (225,)\n",
        "# Convert 'chroma_stft_sum' to a numeric type\n",
        "chroma_stft_sum_numeric = pd.to_numeric(demo_x['chroma_stft_sum'], errors='coerce')\n",
        "\n",
        "# Now convert to a NumPy array, ensuring a numeric dtype\n",
        "chroma_stft_sum_numpy = np.array(chroma_stft_sum_numeric, dtype=float)\n",
        "\n",
        "# Finally, convert this to a PyTorch tensor\n",
        "demo_stft_sum_tensor = torch.tensor(chroma_stft_sum_numpy, dtype=torch.float)\n",
        "#demo_stft_sum_tensor = torch.tensor(demo_x['chroma_stft_sum'].values, dtype=torch.float)\n",
        "\n",
        "## Unsqueezing chroma_stft_sum_tensor to make its shape (225, 1) for concatenation\n",
        "demo_sum_unsqez = demo_stft_sum_tensor.unsqueeze(1)\n",
        "\n",
        "## Concatenate along the second dimension to get a unified tensor of shape (225, 13)\n",
        "# this is X\n",
        "unified_tensor = torch.cat((demo_stft_mean_tensor, demo_sum_unsqez), dim=1)\n",
        "\n",
        "unified_tensor.shape\n",
        "\n",
        "## Convert labels to tensor\n",
        "# this is Y - shape (225,)\n",
        "demo_y_num = pd.to_numeric(demo_y, errors='coerce')\n",
        "demo_y_array = np.array(demo_y_num, dtype=float)\n",
        "demo_y = torch.tensor(demo_y_array, dtype=torch.float)\n",
        "# Finished converting both inputs and labels into tensor\n",
        "### Xiyah ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSn8MKivr_SF"
      },
      "outputs": [],
      "source": [
        "# important\n",
        "demo_y = demo_y - 1  # Shift labels from 1, 2, 3, 4 to 0, 1, 2, 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0qQ5fE1sGCw",
        "outputId": "0748b50e-8765-40ea-bc4b-0727710496b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTum7yNFoYbG"
      },
      "outputs": [],
      "source": [
        "# built a simple NN\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(1187, 128)  # Input layer with 13 features\n",
        "        self.fc2 = nn.Linear(128, 64)  # Hidden layer\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 4)   # Output layer with 4 outputs for 4 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))  # Activation function for hidden layers\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)  # No activation function here, nn.CrossEntropyLoss() will apply softmax\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBqpXBQxp8dc"
      },
      "outputs": [],
      "source": [
        "# run model\n",
        "model = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()  # Cross Entropy Loss for multi-class classification\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyTGla4DqMGE",
        "outputId": "36891ce0-c55d-4615-f439-6a662d1d7ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: nan\n"
          ]
        }
      ],
      "source": [
        "# Simple example using only forward pass\n",
        "labels = demo_y.long()  # Ensure labels are of type torch.long\n",
        "\n",
        "# Forward pass\n",
        "outputs = model(tensor_list)\n",
        "\n",
        "# Compute Loss\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "print(\"Loss:\", loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVmHpA_HaxTM",
        "outputId": "c1140762-1c45-4945-c656-d9eb47b7f2df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7.4081e+02,  1.0533e+02,  1.7182e+00, -1.0368e+03],\n",
              "        [ 3.5262e+03,  4.7966e+02, -1.0303e+01, -4.7296e+03],\n",
              "        [ 2.0975e+03,  2.8689e+02, -5.4511e+00, -2.8098e+03],\n",
              "        ...,\n",
              "        [ 5.4489e+02,  8.3613e+01, -5.7192e+00, -7.5185e+02],\n",
              "        [ 3.0893e+02,  4.4940e+01, -2.1656e+00, -4.2538e+02],\n",
              "        [ 9.7906e+02,  1.1161e+02,  4.9008e+00, -1.3132e+03]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87jjRys3qgtS",
        "outputId": "e589e49d-c503-4e0b-e1d0-9e466ac884b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([225, 13])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unified_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p-Vggh5q0TS",
        "outputId": "39280ffc-5f37-40e4-b78b-1f6bb32745ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# print(outputs)\n",
        "probabilities = torch.softmax(outputs, dim=1)\n",
        "#print(probabilities)\n",
        "_, predicted_classes = torch.max(probabilities, 1)\n",
        "print(predicted_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeSLnn7s-aKM",
        "outputId": "49cd7750-a4ed-4995-827f-3adfd58551d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(225, 12, 1297)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Haoruo ###\n",
        "#Data cleaning mean body\n",
        "df_q1_after=pd.DataFrame()\n",
        "#For chroma_stft\n",
        "\n",
        "##For chroma_stft_origin 我们需要填补空缺值 (225, 12, 1295)\n",
        "data = df_q1['chroma_stft_demos'].values.reshape((225, 1))\n",
        "data_sequences = []\n",
        "sequences = []\n",
        "for i in data:\n",
        "  sequences.append(i[0])\n",
        "max_len = max(s.shape[1] for s in sequences)\n",
        "padded_sequences_all = []\n",
        "for seq in sequences:\n",
        "  padded_sequences = []\n",
        "  for s in seq:\n",
        "    padded_sequences.append(np.append(s,np.zeros((max_len-len(s),))))\n",
        "  padded_sequences_all.append(np.array(padded_sequences))\n",
        "np.array(padded_sequences_all).shape\n",
        "# print(df_q1_after[\"chroma_stft\"].shape)\n",
        "# ##For chroma_stft_mean\n",
        "# sequences = []\n",
        "# for i in df_q1['chroma_stft_mean'].values.reshape((225,1)):\n",
        "#   sequences.append(i[0])\n",
        "# df_q1_after[\"chroma_stft_mean\"]=np.array(sequences).reshape((225, 12,1))\n",
        "\n",
        "# ##For chroma_stft_std\n",
        "# sequences = []\n",
        "# for i in df_q1['chroma_stft_std'].values.reshape((225,1)):\n",
        "#   sequences.append(i[0])\n",
        "# df_q1_after[\"chroma_stft_std\"]=np.array(sequences).reshape((225, 12,1))\n",
        "\n",
        "# ##For chroma_stft_skew\n",
        "# sequences = []\n",
        "# for i in df_q1['chroma_stft_skew'].values.reshape((225,1)):\n",
        "#   sequences.append(i[0])\n",
        "# df_q1_after[\"chroma_stft_skew\"]=np.array(sequences).reshape((225, 12,1))\n",
        "\n",
        "# ##For chroma_stft_kurtosis\n",
        "# sequences = []\n",
        "# for i in df_q1['chroma_stft_kurtosis'].values.reshape((225,1)):\n",
        "#   sequences.append(i[0])\n",
        "# df_q1_after[\"chroma_stft_kurtosis\"]=np.array(sequences).reshape((225, 12,1))\n",
        "\n",
        "### Haoruo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jriD5lVhLEG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inIvToDnf16P",
        "outputId": "f2aaf814-9bf0-429c-958c-b7b9bbbefa11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.36104006]\n",
            " [0.2428113 ]\n",
            " [0.33913192]\n",
            " [0.41598046]\n",
            " [0.2915763 ]\n",
            " [0.30554944]\n",
            " [0.28725767]\n",
            " [0.39951402]\n",
            " [0.43674076]\n",
            " [0.42523807]\n",
            " [0.5881421 ]\n",
            " [0.4389887 ]]\n"
          ]
        }
      ],
      "source": [
        "sequences = []\n",
        "for i in df_q1['chroma_stft_mean'].values.reshape((225,1)):\n",
        "  sequences.append(i[0])\n",
        "print(np.array(sequences).reshape((225, 12,1)))\n",
        "# print(df_q1['chroma_stft_std'].shape)\n",
        "# print(df_q1['chroma_stft_skew'].shape)\n",
        "# print(df_q1['chroma_stft_kurtosis'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZFSW2U8xhlu"
      },
      "source": [
        "# Algorithm Implementation\n",
        "Xiangyu: The following is a implementation of XLNet as a base model (inspired by article https://link.springer.com/chapter/10.1007/978-3-030-72240-1_12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFTnFY0Dxb1q"
      },
      "outputs": [],
      "source": [
        "###Xiangyu###\n",
        "# transformer based model\n",
        "class multitask_model(nn.Module):\n",
        "    def __init__(self, transformer):\n",
        "        super(multitask_model, self).__init__()\n",
        "        self.transformer = transformer\n",
        "        self.fc_middle = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(13, 64),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.fc_quadrant = nn.Sequential(\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.Linear(32, 4),\n",
        "        )\n",
        "    def forward(self, b_input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        outputs = self.transformer(b_input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, labels=labels)\n",
        "        output = self.fc_middle(outputs[1])\n",
        "        fc_quadrant_out = self.fc_quadrant(output)\n",
        "        return fc_quadrant_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4RCNTgN2vta"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QXBQWj4i3BbD",
        "outputId": "61b6566b-95ff-4f7d-f100-5179bf9a5ddf"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "expected np.ndarray (got DataFrame)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-07147379572a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemo_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got DataFrame)"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(demo_x, demo_y, test_size=0.2, random_state=42)\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_test= torch.from_numpy(X_test).float()\n",
        "y_train = torch.from_numpy(y_train).float()\n",
        "y_test = torch.from_numpy(y_test).float()\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLNmzAhc2JZP"
      },
      "outputs": [],
      "source": [
        "###Xiangyu###\n",
        "# train and evaluation\n",
        "def train(i):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_predicted_label = np.array([])\n",
        "    total_actual_label = np.array([])\n",
        "    train_len = 0\n",
        "    f_acc = 0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        if b_labels.size(0) <= 1:\n",
        "            continue\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        pred = outputs[1].detach().cpu().numpy()\n",
        "        batch_f_acc, pred_flat = flat_accuracy(pred, b_labels)\n",
        "        f_acc += batch_f_acc\n",
        "        loss = outputs[0]\n",
        "        loss.sum().backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        labels_flat = b_labels.flatten().cpu().detach().numpy()\n",
        "        total_actual_label = np.concatenate((total_actual_label, labels_flat))\n",
        "        total_predicted_label = np.concatenate((total_predicted_label, pred_flat))\n",
        "\n",
        "        total_loss += outputs[0].sum()\n",
        "        train_len += b_input_ids.size(0)\n",
        "\n",
        "        if step%100 == 0 and step:\n",
        "            precision, recall, f1_measure, _ =  precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
        "            logging.info(\"Train: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" %(train_len*100.0/train_inputs.size(0), i, step,total_loss/train_len, f_acc*100.0/train_len,precision*100., recall*100., f1_measure*100.))\n",
        "\n",
        "        # if torch.cuda.device_count() > 1:\n",
        "        #     p = 100\n",
        "        #     path = save_model_path + '/e_' + str(i) + \"_\" + str(p) + \".ckpt\"\n",
        "        #     torch.save(model.module.state_dict(), path)\n",
        "        # else:\n",
        "        #     torch.save(model.state_dict(), path)\n",
        "\n",
        "    precision, recall, f1_measure, _ = precision_recall_fscore_support(total_actual_label, total_predicted_label, average='macro')\n",
        "    logging.info(\"Train: %5.1f\\tEpoch: %d\\tIter: %d\\tLoss: %5.5f\\tAcc= %5.3f\\tPrecision= %5.3f\\tRecall= %5.3f\\tF1_score= %5.3f\" %(train_len*100.0/train_inputs.size(0), i, step,total_loss/train_len, f_acc*100.0/train_len, precision*100., recall*100., f1_measure*100.))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7SydIJCrKHT"
      },
      "source": [
        "# Updates\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rXAJkxiJeFil",
        "pWTwdI71AFJL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
